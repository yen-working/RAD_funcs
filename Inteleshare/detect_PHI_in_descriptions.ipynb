{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In imaging studies, PHI is generally wiped out by applying anonymization rules on DICOM tags, combined with the CRPs' efforts to delete series with PHI, or redact information burned on the images.\n",
    "\n",
    "However, in rare cases, PHI might come through in studies/series' descriptions. For example, the description would include the subjects' names.\n",
    "\n",
    "# Solution\n",
    "\n",
    "Using NLTK library, the notebook finds low frequencies words in the studies uploaded to the specified Inteleshare project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "### 1. Setup Inteleshare project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AMBRA_Utils\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from nltk import FreqDist, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambra_account_name = \"MOST\"\n",
    "ambra = AMBRA_Utils.utilities.get_api()\n",
    "account = ambra.get_account_by_name(ambra_account_name)\n",
    "namespace = account.get_location_by_name(\"3 - Assigned Studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get all studies and series' descriptions frequency dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phi_excel(file_name: str, data: list):\n",
    "    \"\"\"\n",
    "    Create an excel which user can mark which word is PHI\n",
    "    in `data`.\n",
    "\n",
    "    Inputs:\n",
    "    --------\n",
    "    file_name (str):\n",
    "        Excel file name.\n",
    "\n",
    "    data (list):\n",
    "        List of tuples (`word`, `frequency`).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_records(data, columns=[\"word\", \"frequency\"])\n",
    "    df[\"PHI\"] = \"\"\n",
    "    df.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = list(namespace.get_studies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_desc_tokens = []\n",
    "series_desc_tokens = []\n",
    "series_study_map = dict()\n",
    "\n",
    "for study in studies:\n",
    "    study_tokens = word_tokenize(\n",
    "        \" \".join(study.formatted_description.split(\"_\")).lower()\n",
    "    )\n",
    "    studies_desc_tokens.append(study_tokens)\n",
    "\n",
    "    series = study.get_series()\n",
    "    for s in series:\n",
    "        s_desc_split = s.formatted_description.split(\"_\")\n",
    "        s_desc_split = [char.lower() for char in s_desc_split]\n",
    "        for word in s_desc_split:\n",
    "            if word not in series_study_map:\n",
    "                series_study_map[word] = []\n",
    "            series_study_map[word].append(study)\n",
    "\n",
    "        s_tokens = word_tokenize(\" \".join(s_desc_split))\n",
    "        series_desc_tokens.append(s_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mra', 47),\n",
       " ('rapid', 39),\n",
       " ('hrs', 31),\n",
       " ('72', 15),\n",
       " ('36', 15),\n",
       " ('spine', 9),\n",
       " ('c', 8),\n",
       " ('perfusion', 8),\n",
       " ('summary', 7),\n",
       " ('automated', 6),\n",
       " ('48', 5),\n",
       " ('hours', 4),\n",
       " ('viz', 4),\n",
       " ('no', 4),\n",
       " ('2', 3),\n",
       " ('time', 3),\n",
       " ('msu', 3),\n",
       " ('hemicrani', 2),\n",
       " ('braiin', 2),\n",
       " ('baseliine', 2),\n",
       " ('t', 2),\n",
       " ('event', 2),\n",
       " ('incomplete', 1),\n",
       " ('study', 1),\n",
       " ('mrp', 1),\n",
       " ('very', 1),\n",
       " ('12', 1),\n",
       " ('06pm', 1),\n",
       " ('vs', 1),\n",
       " ('am', 1),\n",
       " ('not', 1),\n",
       " ('included', 1),\n",
       " ('in', 1),\n",
       " ('dicom', 1),\n",
       " ('header', 1),\n",
       " ('correct', 1),\n",
       " ('date', 1),\n",
       " ('9', 1),\n",
       " ('25', 1),\n",
       " ('22', 1),\n",
       " ('at', 1),\n",
       " ('01', 1),\n",
       " ('45am', 1),\n",
       " ('72hrs', 1),\n",
       " ('xa', 1),\n",
       " ('reprocessed', 1),\n",
       " ('lica', 1),\n",
       " ('stenting', 1),\n",
       " ('unscheduled1', 1),\n",
       " ('l', 1),\n",
       " ('2nd', 1),\n",
       " ('enrolling', 1),\n",
       " ('basline', 1),\n",
       " ('baseine', 1),\n",
       " ('image', 1),\n",
       " ('vpct', 1),\n",
       " ('ncct', 1),\n",
       " ('processing', 1),\n",
       " ('failure', 1),\n",
       " ('read', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Studies\n",
    "\n",
    "studies_desc_tokens_flat = list(itertools.chain.from_iterable(studies_desc_tokens))\n",
    "studies_desc_freq = FreqDist(studies_desc_tokens_flat)\n",
    "\n",
    "# Get least frequent\n",
    "num = 60\n",
    "studies_least_common = studies_desc_freq.most_common()[-num:]\n",
    "\n",
    "# Manually check if studies desc contains PHI\n",
    "studies_least_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_phi_excel(f\"studies_phi_{datetime.now()}.xlsx\", studies_least_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series\n",
    "\n",
    "series_desc_tokens_flat = list(itertools.chain.from_iterable(series_desc_tokens))\n",
    "\n",
    "# Get rid of hash strings by ignoring strings with more than 10 characters\n",
    "# and have more than 6 numbers\n",
    "series_desc_tokens_flat_filtered = []\n",
    "for series_token in series_desc_tokens_flat:\n",
    "    num_count = 0\n",
    "    for char in series_token:\n",
    "        if char.isdigit():\n",
    "            num_count += 1\n",
    "\n",
    "    if not (num_count >= 6 and len(series_desc_tokens) >= 10):\n",
    "        series_desc_tokens_flat_filtered.append(series_token)\n",
    "\n",
    "\n",
    "series_desc_freq = FreqDist(series_desc_tokens_flat_filtered)\n",
    "\n",
    "# Get least frequent\n",
    "num = 500\n",
    "series_least_common = series_desc_freq.most_common()[-num:]\n",
    "\n",
    "# Manually check if studies desc contains PHI\n",
    "series_least_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mark PHI or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import Excel into PHI vs non-Phi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redcap-ambra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
