{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Sometimes, some studies don't get segmented after running the `FASTEST_segmentations` DAG, likely because the original itksnap files were wrongly labeled.\n",
    "In such cases, and when it's urgent to get the segmentations numbers, run this notebook.\n",
    "\n",
    "# Solutions\n",
    "Get segmentation numbers for specified files in FASTEST. The code was copied from the `FASTEST_segmentations` DAG, with some changes. It should not update the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import AMBRA_Backups\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "db_name = \"FASTEST\"\n",
    "\n",
    "segmentation_dir = Path(\"/Volumes/FASTEST/Processing/\")\n",
    "assert segmentation_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folders with files that need segmentations\n",
    "need_segmentation = [\n",
    "    Path(\n",
    "        \"/Volumes/FASTEST/Processing/1616/MR_MRI_BRAIN_WO_FOLLOW_UP_3a5de144b716_2024_12_22\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(directory):\n",
    "    info_path = Path(directory).joinpath(\"info.json\")\n",
    "    assert info_path.exists()\n",
    "\n",
    "    with open(info_path, \"r\") as fopen:\n",
    "        data = json.load(fopen)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_study(db_obj, study_uid):\n",
    "    res = db_obj.run_select_query(\n",
    "        \"SELECT id FROM studies WHERE study_uid=%s\", record=(study_uid,)\n",
    "    )\n",
    "    return res[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_info(roi_path):\n",
    "    info = {\"path\": roi_path}\n",
    "\n",
    "    img = nib.load(roi_path)\n",
    "    header = img.header\n",
    "\n",
    "    vox_volume = header[\"pixdim\"][1] * header[\"pixdim\"][2] * header[\"pixdim\"][3]\n",
    "    info[\"vox_volume\"] = vox_volume\n",
    "    info[\"pixdim\"] = header[\"pixdim\"][1:4]\n",
    "    info[\"dim\"] = header[\"dim\"][1:4]\n",
    "    info[\"roi_volumes\"] = []\n",
    "\n",
    "    info[\"timepoint\"] = None\n",
    "    if \"_BL\" in roi_path.name:\n",
    "        info[\"timepoint\"] = \"BL\"\n",
    "    elif \"_FU\" in roi_path.name:\n",
    "        info[\"timepoint\"] = \"FU\"\n",
    "    elif \"_Unsched\" in roi_path.name:\n",
    "        info[\"timepoint\"] = \"US\"\n",
    "    elif \"_US\" in roi_path.name:\n",
    "        info[\"timepoint\"] = \"US\"\n",
    "    elif \"_UN\" in roi_path.name:\n",
    "        info[\"timepoint\"] = \"US\"\n",
    "\n",
    "    data = img.get_fdata()\n",
    "    info[\"non_zero_volume\"] = np.where(data > 0)[0].shape[0] * vox_volume\n",
    "    for index in np.unique(np.unique(data)):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        n_voxels = np.where(data == index)[0].shape[0]\n",
    "        volume = n_voxels * vox_volume\n",
    "        roi_info = {\"index\": index, \"n_voxels\": n_voxels, \"volume\": volume}\n",
    "        info[\"roi_volumes\"].append(roi_info)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_segmentation(db_obj, roi_path, id_study):\n",
    "    roi_path = Path(roi_path)\n",
    "    roi_info = get_roi_info(roi_path)\n",
    "\n",
    "    try:\n",
    "        roi1_volume = float(\n",
    "            [\n",
    "                this[\"volume\"]\n",
    "                for this in roi_info[\"roi_volumes\"]\n",
    "                if int(this[\"index\"]) == 1\n",
    "            ][0]\n",
    "        )\n",
    "    except IndexError:\n",
    "        roi1_volume = 0\n",
    "    try:\n",
    "        roi2_volume = float(\n",
    "            [\n",
    "                this[\"volume\"]\n",
    "                for this in roi_info[\"roi_volumes\"]\n",
    "                if int(this[\"index\"]) == 2\n",
    "            ][0]\n",
    "        )\n",
    "    except IndexError:\n",
    "        roi2_volume = 0\n",
    "    try:\n",
    "        roi3_volume = float(\n",
    "            [\n",
    "                this[\"volume\"]\n",
    "                for this in roi_info[\"roi_volumes\"]\n",
    "                if int(this[\"index\"]) == 3\n",
    "            ][0]\n",
    "        )\n",
    "    except IndexError:\n",
    "        roi3_volume = 0\n",
    "\n",
    "    info_dic = {\n",
    "        \"roi_path\": str(roi_path),\n",
    "        \"id_study\": id_study,\n",
    "        \"timepoint\": roi_info[\"timepoint\"],\n",
    "        \"roi1_volume\": roi1_volume,\n",
    "        \"roi2_volume\": roi2_volume,\n",
    "        \"roi3_volume\": roi3_volume,\n",
    "        \"n_rois\": len(roi_info[\"roi_volumes\"]),\n",
    "        \"vox_dim_x\": float(roi_info[\"pixdim\"][0]),\n",
    "        \"vox_dim_y\": float(roi_info[\"pixdim\"][1]),\n",
    "        \"vox_dim_z\": float(roi_info[\"pixdim\"][2]),\n",
    "        \"stats_added\": datetime.now(),\n",
    "    }\n",
    "    print(\"#######################\")\n",
    "    print(\"info_dict: \")\n",
    "    print(info_dic)\n",
    "    print(\"----------------\")\n",
    "    print(\"relevant info:\")\n",
    "    print(f\"\"\"\n",
    "        roi1_volume_{info_dic[\"timepoint\"]}: {info_dic[\"roi1_volume\"] / 1000}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_segmentations(study_dirs):\n",
    "    db = AMBRA_Backups.database.Database(db_name)\n",
    "\n",
    "    for study_dir in study_dirs:\n",
    "        study_info = read_info(study_dir)\n",
    "        print(\"\\t\", study_dir.name)\n",
    "\n",
    "        nii_files = study_dir.glob(\"*WS*.nii*\")\n",
    "        for nii_file in nii_files:\n",
    "            try:\n",
    "                img = nib.load(nii_file)\n",
    "                img_data = img.get_fdata()\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if np.unique(img_data).shape[0] < 4:\n",
    "                print(\"\\t\\t\", nii_file.name)\n",
    "                print(\"\\t\\t\\tN unique: \", np.unique(img_data).shape[0])\n",
    "                id_study = get_id_study(db, study_info[\"study_uid\"])\n",
    "                print(id_study)\n",
    "\n",
    "                add_segmentation(db, nii_file, id_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_segmentations(need_segmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redcap-ambra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
